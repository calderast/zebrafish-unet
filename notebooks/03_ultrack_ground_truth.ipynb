{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Ground Truth Segmentation Labels with Ultrack\n",
    "\n",
    "This notebook runs the [Ultrack](https://github.com/royerlab/ultrack) segmentation and tracking pipeline on a small subset of the **ZSNS001_tail** zebrafish embryo dataset to generate dense instance segmentation labels for U-Net training.\n",
    "\n",
    "Ultrack's approach:\n",
    "1. **Preprocess**: `detect_foreground` (binary cell mask) + `robust_invert` (boundary/contour map)\n",
    "2. **Segment**: Generate multiple candidate segmentation hypotheses via hierarchical watershed\n",
    "3. **Link**: Find candidate connections between segments in adjacent frames\n",
    "4. **Solve**: Integer Linear Programming (ILP) to select the optimal segmentation + tracking\n",
    "\n",
    "This gives us high-quality instance labels that are temporally consistent — much better than simple thresholding, and avoids the circularity of training a U-Net from another U-Net's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import zarr\n",
    "import dask.array as da\n",
    "from ome_zarr.io import parse_url\n",
    "from ome_zarr.reader import Reader\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from ultrack import MainConfig, Tracker\n",
    "from ultrack.imgproc import robust_invert, detect_foreground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the ZSNS001_tail dataset\n",
    "\n",
    "Same lazy loading as notebook 01. We'll select a small subset of timepoints to keep compute manageable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://public.czbiohub.org/royerlab/zebrahub/imaging/single-objective/ZSNS001_tail.ome.zarr\"\n",
    "\n",
    "reader = Reader(parse_url(URL))\n",
    "nodes = list(reader())\n",
    "dask_data = nodes[0].data\n",
    "\n",
    "data = dask_data[0]  # full resolution\n",
    "print(f\"Full dataset shape (T, C, Z, Y, X): {data.shape}\")\n",
    "print(f\"Dtype: {data.dtype}\")\n",
    "\n",
    "n_t, n_c, n_z, n_y, n_x = data.shape\n",
    "voxel_size = (1.24, 0.439, 0.439)  # Z, Y, X in micrometers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a small subset of timepoints (evenly spaced across development)\n",
    "N_TIMEPOINTS = 5  # start small — increase once you've verified it works\n",
    "selected_times = np.linspace(0, n_t - 1, N_TIMEPOINTS, dtype=int)\n",
    "print(f\"Selected timepoints ({N_TIMEPOINTS}): {selected_times}\")\n",
    "print(f\"Volume per timepoint: {n_z} x {n_y} x {n_x} = {n_z * n_y * n_x / 1e6:.1f}M voxels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing\n",
    "\n",
    "Ultrack requires two inputs:\n",
    "- **Foreground map**: probability/binary mask of where cells are (from `detect_foreground`)\n",
    "- **Contour/edge map**: boundary strength between cells (from `robust_invert`)\n",
    "\n",
    "We preprocess each selected timepoint and stack them into arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the selected timepoints\n",
    "foreground_list = []\n",
    "contour_list = []\n",
    "raw_list = []\n",
    "\n",
    "for i, t in enumerate(selected_times):\n",
    "    print(f\"Processing timepoint {t} ({i+1}/{len(selected_times)})...\", end=\" \")\n",
    "    \n",
    "    # Load the full 3D volume for this timepoint\n",
    "    volume = data[t, 0].compute()  # shape: (Z, Y, X)\n",
    "    raw_list.append(volume)\n",
    "    \n",
    "    # Detect foreground (binary cell mask)\n",
    "    fg = detect_foreground(volume, voxel_size=voxel_size)\n",
    "    foreground_list.append(fg.astype(np.float32))\n",
    "    \n",
    "    # Robust inversion (boundary/contour map)\n",
    "    contours = robust_invert(volume, voxel_size=voxel_size)\n",
    "    contour_list.append(contours)\n",
    "    \n",
    "    print(f\"foreground coverage: {fg.mean()*100:.1f}%\")\n",
    "\n",
    "# Stack into (T, Z, Y, X) arrays\n",
    "foreground_stack = np.stack(foreground_list)\n",
    "contour_stack = np.stack(contour_list)\n",
    "raw_stack = np.stack(raw_list)\n",
    "\n",
    "print(f\"\\nForeground shape: {foreground_stack.shape}\")\n",
    "print(f\"Contour shape: {contour_stack.shape}\")\n",
    "print(f\"Raw shape: {raw_stack.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize preprocessing for the first timepoint\n",
    "t_vis = 0\n",
    "mid_z = n_z // 2\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "raw_slice = raw_stack[t_vis, mid_z]\n",
    "vmin, vmax = np.percentile(raw_slice, [1, 99.5])\n",
    "\n",
    "axes[0].imshow(raw_slice, cmap=\"gray\", vmin=vmin, vmax=vmax)\n",
    "axes[0].set_title(f\"Raw image (t={selected_times[t_vis]}, z={mid_z})\")\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "axes[1].imshow(foreground_stack[t_vis, mid_z], cmap=\"gray\")\n",
    "axes[1].set_title(\"Detected foreground\")\n",
    "axes[1].axis(\"off\")\n",
    "\n",
    "axes[2].imshow(contour_stack[t_vis, mid_z], cmap=\"gray\")\n",
    "axes[2].set_title(\"Contour map (robust_invert)\")\n",
    "axes[2].axis(\"off\")\n",
    "\n",
    "plt.suptitle(\"Ultrack preprocessing\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run the Ultrack pipeline\n",
    "\n",
    "Configure the tracker with parameters from the [Zebrahub example](https://github.com/royerlab/ultrack/tree/main/examples/zebrahub) and run segmentation + linking + ILP solving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Ultrack (parameters from the zebrahub example)\n",
    "config = MainConfig()\n",
    "\n",
    "# Segmentation parameters\n",
    "config.segmentation_config.threshold = 0.5\n",
    "config.segmentation_config.min_area = 500\n",
    "config.segmentation_config.max_area = 10_000\n",
    "config.segmentation_config.n_workers = 1\n",
    "\n",
    "# Linking parameters\n",
    "config.linking_config.max_distance = 5.0\n",
    "config.linking_config.max_neighbors = 5\n",
    "config.linking_config.n_workers = 1\n",
    "\n",
    "# Tracking/solving parameters\n",
    "config.tracking_config.appear_weight = -0.002\n",
    "config.tracking_config.disappear_weight = -0.01\n",
    "config.tracking_config.division_weight = -0.001\n",
    "config.tracking_config.window_size = max(N_TIMEPOINTS, 5)\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  Segmentation: min_area={config.segmentation_config.min_area}, \"\n",
    "      f\"max_area={config.segmentation_config.max_area}, \"\n",
    "      f\"threshold={config.segmentation_config.threshold}\")\n",
    "print(f\"  Linking: max_distance={config.linking_config.max_distance}, \"\n",
    "      f\"max_neighbors={config.linking_config.max_neighbors}\")\n",
    "print(f\"  Tracking: window_size={config.tracking_config.window_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the full pipeline\n",
    "tracker = Tracker(config)\n",
    "\n",
    "print(\"Running Ultrack pipeline...\")\n",
    "print(\"  This may take several minutes per timepoint.\")\n",
    "print(f\"  Processing {N_TIMEPOINTS} timepoints of shape ({n_z}, {n_y}, {n_x})\\n\")\n",
    "\n",
    "tracker.track(\n",
    "    foreground=foreground_stack,\n",
    "    edges=contour_stack,\n",
    ")\n",
    "\n",
    "print(\"\\nPipeline complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Export dense instance labels\n",
    "\n",
    "Extract the dense (T, Z, Y, X) label array where each voxel is assigned its instance/track ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to dense label array\n",
    "OUTPUT_DIR = Path(\"../data/ground_truth\")\n",
    "LABELS_PATH = OUTPUT_DIR / \"labels.zarr\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "labels = tracker.to_zarr(\n",
    "    time_points=N_TIMEPOINTS,\n",
    "    store_or_path=str(LABELS_PATH),\n",
    "    overwrite=True,\n",
    ")\n",
    "\n",
    "print(f\"Labels shape: {labels.shape}\")\n",
    "print(f\"Labels dtype: {labels.dtype}\")\n",
    "print(f\"Saved to: {LABELS_PATH.resolve()}\")\n",
    "\n",
    "# Count instances per timepoint\n",
    "for t in range(labels.shape[0]):\n",
    "    n_instances = len(np.unique(labels[t])) - 1  # subtract background (0)\n",
    "    print(f\"  t={selected_times[t]}: {n_instances} cell instances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize: raw image + instance labels for each timepoint\n",
    "n_show = min(N_TIMEPOINTS, 5)\n",
    "fig, axes = plt.subplots(2, n_show, figsize=(5 * n_show, 10))\n",
    "if n_show == 1:\n",
    "    axes = axes.reshape(2, 1)\n",
    "\n",
    "# Random colormap for instance labels\n",
    "max_label = max(int(labels[t, mid_z].max()) for t in range(n_show))\n",
    "rand_cmap = ListedColormap(np.random.default_rng(42).random((max(max_label + 1, 2), 3)))\n",
    "rand_cmap.colors[0] = [0, 0, 0]  # background = black\n",
    "\n",
    "for i in range(n_show):\n",
    "    raw_slice = raw_stack[i, mid_z]\n",
    "    label_slice = labels[i, mid_z]\n",
    "    vmin, vmax = np.percentile(raw_slice, [1, 99.5])\n",
    "    \n",
    "    axes[0, i].imshow(raw_slice, cmap=\"gray\", vmin=vmin, vmax=vmax)\n",
    "    axes[0, i].set_title(f\"t={selected_times[i]}\")\n",
    "    axes[0, i].axis(\"off\")\n",
    "    \n",
    "    axes[1, i].imshow(label_slice, cmap=rand_cmap, interpolation=\"nearest\")\n",
    "    n_inst = len(np.unique(label_slice)) - 1\n",
    "    axes[1, i].set_title(f\"{n_inst} instances\")\n",
    "    axes[1, i].axis(\"off\")\n",
    "\n",
    "axes[0, 0].set_ylabel(\"Raw\", fontsize=12)\n",
    "axes[1, 0].set_ylabel(\"Instance labels\", fontsize=12)\n",
    "plt.suptitle(f\"Ultrack instance segmentation (z={mid_z})\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overlay: raw image with label boundaries\n",
    "from skimage.segmentation import find_boundaries\n",
    "\n",
    "t_vis = 0\n",
    "raw_slice = raw_stack[t_vis, mid_z]\n",
    "label_slice = labels[t_vis, mid_z]\n",
    "vmin, vmax = np.percentile(raw_slice, [1, 99.5])\n",
    "\n",
    "boundaries = find_boundaries(label_slice, mode=\"outer\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "ax.imshow(raw_slice, cmap=\"gray\", vmin=vmin, vmax=vmax)\n",
    "ax.imshow(np.ma.masked_where(~boundaries, boundaries), cmap=\"spring\", alpha=0.8)\n",
    "ax.set_title(f\"Raw + Ultrack boundaries (t={selected_times[t_vis]}, z={mid_z})\")\n",
    "ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Extract paired training patches\n",
    "\n",
    "Create (image, mask) pairs for U-Net training. Each pair is a 256x256 XY patch with:\n",
    "- `images/`: float32 normalized to [0, 1]\n",
    "- `masks/`: int32 instance label map (0 = background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATCH_SIZE = 256\n",
    "PATCHES_PER_SLICE = 4\n",
    "MIN_FOREGROUND = 0.1  # skip patches with <10% labeled pixels\n",
    "\n",
    "IMG_DIR = OUTPUT_DIR / \"images\"\n",
    "MASK_DIR = OUTPUT_DIR / \"masks\"\n",
    "IMG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "MASK_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "patch_count = 0\n",
    "\n",
    "# Sample z-slices from the middle 50% of the volume (edges are often empty)\n",
    "z_start = n_z // 4\n",
    "z_end = 3 * n_z // 4\n",
    "sample_zs = np.linspace(z_start, z_end, 5, dtype=int)\n",
    "\n",
    "for t_idx in range(N_TIMEPOINTS):\n",
    "    for z in sample_zs:\n",
    "        raw_slice = raw_stack[t_idx, z].astype(np.float32)\n",
    "        \n",
    "        # Quantile-normalize to [0, 1]\n",
    "        lo, hi = np.percentile(raw_slice, [0.1, 99.9])\n",
    "        img_norm = np.clip((raw_slice - lo) / max(hi - lo, 1e-8), 0, 1)\n",
    "        \n",
    "        label_slice = np.array(labels[t_idx, z])\n",
    "        \n",
    "        for p in range(PATCHES_PER_SLICE):\n",
    "            y0 = rng.integers(0, n_y - PATCH_SIZE)\n",
    "            x0 = rng.integers(0, n_x - PATCH_SIZE)\n",
    "            \n",
    "            img_patch = img_norm[y0:y0+PATCH_SIZE, x0:x0+PATCH_SIZE]\n",
    "            mask_patch = label_slice[y0:y0+PATCH_SIZE, x0:x0+PATCH_SIZE]\n",
    "            \n",
    "            # Skip patches with too little signal\n",
    "            fg_frac = (mask_patch > 0).mean()\n",
    "            if fg_frac < MIN_FOREGROUND:\n",
    "                continue\n",
    "            \n",
    "            t_real = selected_times[t_idx]\n",
    "            fname = f\"t{t_real:04d}_z{z:03d}_y{y0:04d}_x{x0:04d}\"\n",
    "            np.save(IMG_DIR / f\"{fname}_img.npy\", img_patch.astype(np.float32))\n",
    "            np.save(MASK_DIR / f\"{fname}_mask.npy\", mask_patch.astype(np.int32))\n",
    "            patch_count += 1\n",
    "\n",
    "print(f\"Saved {patch_count} training pairs\")\n",
    "print(f\"  Images: {IMG_DIR.resolve()}\")\n",
    "print(f\"  Masks:  {MASK_DIR.resolve()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize saved training pairs\n",
    "saved_imgs = sorted(IMG_DIR.glob(\"*_img.npy\"))\n",
    "n_show = min(6, len(saved_imgs))\n",
    "\n",
    "fig, axes = plt.subplots(2, n_show, figsize=(4 * n_show, 8))\n",
    "if n_show == 1:\n",
    "    axes = axes.reshape(2, 1)\n",
    "\n",
    "for i in range(n_show):\n",
    "    img = np.load(saved_imgs[i])\n",
    "    mask = np.load(str(saved_imgs[i]).replace(\"_img.npy\", \"_mask.npy\"))\n",
    "    \n",
    "    axes[0, i].imshow(img, cmap=\"gray\", vmin=0, vmax=1)\n",
    "    axes[0, i].set_title(saved_imgs[i].stem.replace(\"_img\", \"\"), fontsize=7)\n",
    "    axes[0, i].axis(\"off\")\n",
    "    \n",
    "    n_cells = len(np.unique(mask)) - 1\n",
    "    cmap = ListedColormap(np.random.default_rng(42).random((max(n_cells + 1, 2), 3)))\n",
    "    cmap.colors[0] = [0, 0, 0]\n",
    "    axes[1, i].imshow(mask, cmap=cmap, interpolation=\"nearest\")\n",
    "    axes[1, i].set_title(f\"{n_cells} cells\", fontsize=8)\n",
    "    axes[1, i].axis(\"off\")\n",
    "\n",
    "axes[0, 0].set_ylabel(\"Raw (normalized)\", fontsize=10)\n",
    "axes[1, 0].set_ylabel(\"Instance mask\", fontsize=10)\n",
    "plt.suptitle(\"Training patch pairs\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Label quality assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import regionprops\n",
    "\n",
    "all_areas = []\n",
    "cells_per_patch = []\n",
    "\n",
    "for mask_path in sorted(MASK_DIR.glob(\"*_mask.npy\")):\n",
    "    mask = np.load(mask_path)\n",
    "    props = regionprops(mask)\n",
    "    areas = [p.area for p in props]\n",
    "    all_areas.extend(areas)\n",
    "    cells_per_patch.append(len(props))\n",
    "\n",
    "all_areas = np.array(all_areas)\n",
    "\n",
    "print(f\"Total patches: {len(cells_per_patch)}\")\n",
    "print(f\"Total cell instances: {len(all_areas)}\")\n",
    "print(f\"Cells per patch: {np.mean(cells_per_patch):.1f} +/- {np.std(cells_per_patch):.1f}\")\n",
    "print(f\"Cell area (pixels): median={np.median(all_areas):.0f}, \"\n",
    "      f\"mean={np.mean(all_areas):.0f}, std={np.std(all_areas):.0f}\")\n",
    "print(f\"Cell area range: [{all_areas.min()}, {all_areas.max()}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].hist(all_areas, bins=50, edgecolor=\"black\")\n",
    "axes[0].set_xlabel(\"Cell area (pixels)\")\n",
    "axes[0].set_ylabel(\"Count\")\n",
    "axes[0].set_title(\"Cell size distribution\")\n",
    "\n",
    "axes[1].hist(cells_per_patch, bins=range(0, max(cells_per_patch) + 2), edgecolor=\"black\")\n",
    "axes[1].set_xlabel(\"Number of cells\")\n",
    "axes[1].set_ylabel(\"Number of patches\")\n",
    "axes[1].set_title(\"Cells per patch\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "- **Scale up**: Increase `N_TIMEPOINTS` to generate more training data (the pipeline processes one frame at a time, so RAM isn't a bottleneck)\n",
    "- **Manual inspection**: Review a sample of patches in napari or QuPath to verify label quality\n",
    "- **Data augmentation**: Plan flips, rotations, intensity jitter for training\n",
    "- **Train/val split**: Hold out entire timepoints for validation to test generalization across developmental stages\n",
    "- **U-Net training**: Build a PyTorch DataLoader from these patches and train a segmentation model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
